# Project_7_ML

![tendencias-sector-inmobiliario](https://github.com/luisgh87/Project_7_ML/assets/116723919/ad336873-8f48-453c-982b-27c34a926d4f)


# Introducci√≥n

Este proyecto tiene como objetivo abordar una pregunta clave para viajeros y anfitriones por igual: ¬øcu√°nto deber√≠a costar una estancia en una ubicaci√≥n espec√≠fica en los EE. UU.? Al aprovechar t√©cnicas avanzadas de an√°lisis de datos y machine learning, nos sumergiremos en un oc√©ano de variables, desde la ubicaci√≥n geogr√°fica y las comodidades del alojamiento hasta las tendencias del mercado y eventos locales.

La capacidad de predecir con precisi√≥n los precios no solo beneficia a los viajeros al planificar su presupuesto, sino que tambi√©n brinda a los anfitriones una visi√≥n estrat√©gica para establecer tarifas competitivas y atractivas. Este proyecto no solo es una exploraci√≥n de datos, sino una puerta abierta a la optimizaci√≥n de experiencias de viaje y a un mercado de alojamientos m√°s transparente y eficiente.

Acomp√°√±anos en este viaje anal√≠tico mientras desentra√±amos patrones, identificamos factores clave y creamos un modelo predictivo robusto que ilumine el fascinante universo de los precios de Airbnb en los Estados Unidos. ¬°Bienvenidos a un futuro donde cada viaje es una experiencia a√∫n m√°s personalizada y accesible! üåçüè°‚ú®

# Data Cleansing

1. Examinamos los dataframes de train y test
2. Buscamos una alta correlaci√≥n entre las variables num√©ricas para evitar problemas de multicolinealidad y overfitting, pero no se aprecian en el heatmap. S√≥lo entre la "latitud" y la "longitud", pero ambas ser√°n necesarias y complementarias.
3. Covertimos a valores num√©ricos todas las columnas de valor para nuestro modelo predictivo con la ayuda de LabelEncoder y One Hot Encoding. Desechamos las que no aporten nada.
4. Tratamos de clusterizar en agrupaciones de 10 valores distintos los datos de las columnas num√©ricas, sirviendo esto para reducir el ruido centr√°ndonos en las caracter√≠sticas principales y simplificar el modelo.
5. Descomponemos la columna "amenities" en otras nuevas en proporci√≥n a su numero y las integramos a los dataframes para facilitar su posterior interpretaci√≥n.
6. Aunque carecemos de un gran n√∫mero de missing values, los rellenaremos con la moda de los valores de sus respectivas series.
7. Para finalizar el proceso de limpieza de datos, daremos el mismo orden y n√∫mero de columnas al train y al test, necesario para un correcto entrenamiento de los datos.

# Entrenamiento y predicci√≥n

Para el relizamiento de estas tareas hicimos uso de tres modelos de entrenamiento:

1. LinearRegression
2. Decision Tree Regressor
3. Random Forest Regressor

√âste √∫ltimo fue el que mejores resultados predictivos para los precios de los establecimientos ofrecidos por Airbnb. Puede que por los siguientes motivos:

- Random Forest puede ser m√°s adecuado para capturar patrones complejos o relaciones no lineales en los datos.
- Mitiga mejor el problema de overfiting al promediar las predicciones de varios √°rboles, lo que puede resultar en un modelo m√°s robusto y generalizable que Decision Tree.
- Random Forest tiene la capacidad inherente de manejar caracter√≠sticas relevantes al construir √°rboles con subconjuntos aleatorios de caracter√≠sticas. Esto puede ser beneficioso cuando tienes un conjunto de datos con muchas caracter√≠sticas, algunas de las cuales pueden no ser informativas para la tarea de regresi√≥n.
- Es un algoritmo m√°s robusto frente a outliers en comparaci√≥n con Linear Regression. Los √°rboles de decisi√≥n no se ven tan afectados por valores at√≠picos y pueden adaptarse mejor a la variabilidad en los datos.
- No hace suposiciones estrictas sobre la distribuci√≥n de los datos, a diferencia de Linear Regression, que asume una relaci√≥n lineal entre las variables independientes y dependientes.
- Random Forest tiende a ser m√°s f√°cil de usar y generalmente requiere menos ajuste de hiperpar√°metros, simplificando el proceso de modelado y aumentar la probabilidad de obtener buenos resultados sin mucha afinaci√≥n.

# Observaciones

- Decidimos no normalizar el dato con Standard Scaler o MinMaxScaler porque no daba los resultados esperados, empeorando el modelo.
- Conseguimos mejorar el resultado a posterioiri eliminando la columna "id". A pesar de ser num√©rica, ten√≠a un efecto categ√≥rico que empobrec√≠a la predicci√≥n,
